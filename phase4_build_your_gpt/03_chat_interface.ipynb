{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 4, Lesson 3: Chat Interface with Gradio",
        "",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/suraaj3poudel/Learn-To-Make-GPT-Model/blob/main/phase4_build_your_gpt/03_chat_interface.ipynb)",
        "",
        "Build an interactive chat interface for your GPT! \ud83d\udcac",
        "",
        "## What You'll Learn",
        "1. Using Gradio for UI",
        "2. Chat-style interactions",
        "3. Prompt engineering",
        "4. Temperature and sampling controls",
        "5. Deploying your chatbot",
        "",
        "The final wow moment! \ud83c\udf89"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Setup",
        "import torch",
        "import torch.nn.functional as F",
        "import gradio as gr",
        "",
        "print('\u2705 Ready to build a chat interface!')",
        "print('Make sure you have gradio installed: pip install gradio')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Trained Model",
        "",
        "First, load your trained GPT model from Lesson 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# For this demo, we'll create a mock model",
        "# In practice, load your actual trained model",
        "",
        "class MockGPT:",
        "    \"\"\"Mock GPT for demonstration\"\"\"",
        "    def __init__(self):",
        "        self.name = \"Mini-GPT\"",
        "    ",
        "    def generate(self, prompt, max_length=100, temperature=0.8):",
        "        # This is a mock - replace with your actual model",
        "        responses = [",
        "            f\"Based on '{prompt}', I would say that machine learning is fascinating!\",",
        "            f\"That's an interesting question about '{prompt}'. Let me think...\",",
        "            f\"Regarding '{prompt}', here's what I know: AI is transforming technology.\",",
        "        ]",
        "        import random",
        "        return random.choice(responses) + \" \" + prompt",
        "",
        "# In practice, replace with:",
        "# model = load_model('gpt_checkpoint.pt')",
        "",
        "model = MockGPT()",
        "print(\"\u2705 Model loaded (using mock for demo)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Generation Function",
        "",
        "Function to generate responses from the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def generate_response(prompt, max_length=150, temperature=0.8, top_k=50):",
        "    \"\"\"",
        "    Generate response from the model",
        "    ",
        "    Args:",
        "        prompt: User input text",
        "        max_length: Maximum tokens to generate",
        "        temperature: Sampling temperature (higher = more creative)",
        "        top_k: Only sample from top k tokens",
        "    ",
        "    Returns:",
        "        Generated text",
        "    \"\"\"",
        "    if not prompt.strip():",
        "        return \"Please enter a message!\"",
        "    ",
        "    # Generate",
        "    response = model.generate(",
        "        prompt=prompt,",
        "        max_length=max_length,",
        "        temperature=temperature",
        "    )",
        "    ",
        "    return response",
        "",
        "# Test",
        "test_prompt = \"What is machine learning?\"",
        "response = generate_response(test_prompt)",
        "print(f\"Prompt: {test_prompt}\")",
        "print(f\"Response: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build Gradio Interface",
        "",
        "Create a beautiful chat interface!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def chat_interface(message, history, temperature, max_length):",
        "    \"\"\"",
        "    Chat function for Gradio",
        "    ",
        "    Args:",
        "        message: User's message",
        "        history: Chat history",
        "        temperature: Sampling temperature",
        "        max_length: Max tokens to generate",
        "    ",
        "    Returns:",
        "        Updated history",
        "    \"\"\"",
        "    # Generate response",
        "    response = generate_response(",
        "        prompt=message,",
        "        max_length=max_length,",
        "        temperature=temperature",
        "    )",
        "    ",
        "    # Add to history",
        "    history.append((message, response))",
        "    ",
        "    return history",
        "",
        "# Create Gradio interface",
        "with gr.Blocks(title=\"GPT Chat Interface\") as demo:",
        "    gr.Markdown(",
        "        \"\"\"",
        "        # \ud83e\udd16 Chat with Your GPT Model!",
        "        ",
        "        This is your custom-built GPT chatbot. Try asking questions!",
        "        \"\"\"",
        "    )",
        "    ",
        "    chatbot = gr.Chatbot(",
        "        label=\"Chat History\",",
        "        height=400",
        "    )",
        "    ",
        "    with gr.Row():",
        "        msg = gr.Textbox(",
        "            label=\"Your Message\",",
        "            placeholder=\"Type your message here...\",",
        "            scale=4",
        "        )",
        "        send = gr.Button(\"Send\", scale=1)",
        "    ",
        "    with gr.Accordion(\"\u2699\ufe0f Advanced Settings\", open=False):",
        "        temperature = gr.Slider(",
        "            minimum=0.1,",
        "            maximum=2.0,",
        "            value=0.8,",
        "            step=0.1,",
        "            label=\"Temperature (Higher = More Creative)\"",
        "        )",
        "        max_length = gr.Slider(",
        "            minimum=50,",
        "            maximum=500,",
        "            value=150,",
        "            step=10,",
        "            label=\"Max Length\"",
        "        )",
        "    ",
        "    clear = gr.Button(\"Clear Chat\")",
        "    ",
        "    # Event handlers",
        "    msg.submit(chat_interface, [msg, chatbot, temperature, max_length], chatbot)",
        "    msg.submit(lambda: \"\", None, msg)  # Clear input",
        "    ",
        "    send.click(chat_interface, [msg, chatbot, temperature, max_length], chatbot)",
        "    send.click(lambda: \"\", None, msg)  # Clear input",
        "    ",
        "    clear.click(lambda: None, None, chatbot)",
        "    ",
        "    gr.Markdown(",
        "        \"\"\"",
        "        ### \ud83d\udca1 Tips:",
        "        - Adjust temperature for more/less creative responses",
        "        - Higher max length allows longer responses",
        "        - Try different prompts to see what your model learned!",
        "        \"\"\"",
        "    )",
        "",
        "print(\"\\n\u2705 Gradio interface created!\")",
        "print(\"\\nTo launch, run:\")",
        "print(\"  demo.launch()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Launch the Interface",
        "",
        "Run this cell to start the chat interface!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Launch the interface",
        "# Uncomment to run:",
        "",
        "# demo.launch(",
        "#     share=False,      # Set True to create public link",
        "#     server_name=\"0.0.0.0\",  # Allow external connections",
        "#     server_port=7860",
        "# )",
        "",
        "print(\"Run demo.launch() to start the chat interface!\")",
        "print(\"\\nOptions:\")",
        "print(\"  - share=True: Create a public link (for demos)\")",
        "print(\"  - share=False: Local only (more secure)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prompt Engineering",
        "",
        "Get better responses with good prompts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example prompts",
        "good_prompts = [",
        "    # Specific questions",
        "    \"Explain how transformers work in 2-3 sentences.\",",
        "    ",
        "    # Context setting",
        "    \"As an AI expert, what are the key components of a neural network?\",",
        "    ",
        "    # Format instructions",
        "    \"List 3 benefits of machine learning:\\n1.\",",
        "    ",
        "    # Role playing",
        "    \"You are a helpful AI assistant. Explain deep learning simply.\",",
        "]",
        "",
        "poor_prompts = [",
        "    # Too vague",
        "    \"Tell me stuff\",",
        "    ",
        "    # No context",
        "    \"It\",",
        "    ",
        "    # Too broad",
        "    \"Everything about AI\",",
        "]",
        "",
        "print(\"Good Prompts:\")",
        "for i, prompt in enumerate(good_prompts, 1):",
        "    print(f\"{i}. {prompt}\")",
        "",
        "print(\"\\n\\nPoor Prompts (avoid these):\")",
        "for i, prompt in enumerate(poor_prompts, 1):",
        "    print(f\"{i}. {prompt}\")",
        "",
        "print(\"\\n\ud83d\udca1 Better prompts = better responses!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Advanced Features",
        "",
        "Add more functionality to your chatbot!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def enhanced_chat(message, history, system_prompt=\"You are a helpful AI assistant.\"):",
        "    \"\"\"",
        "    Enhanced chat with system prompt",
        "    ",
        "    Args:",
        "        message: User message",
        "        history: Chat history",
        "        system_prompt: System-level instruction",
        "    \"\"\"",
        "    # Combine system prompt with user message",
        "    full_prompt = f\"{system_prompt}\\n\\nUser: {message}\\nAssistant:\"",
        "    ",
        "    # Generate",
        "    response = generate_response(full_prompt, max_length=200, temperature=0.7)",
        "    ",
        "    return response",
        "",
        "# Example system prompts",
        "system_prompts = {",
        "    \"Helpful Assistant\": \"You are a helpful, friendly AI assistant.\",",
        "    \"Code Helper\": \"You are an expert programmer who explains code clearly.\",",
        "    \"Creative Writer\": \"You are a creative writer who crafts engaging stories.\",",
        "    \"Teacher\": \"You are a patient teacher who explains concepts simply.\",",
        "}",
        "",
        "print(\"System Prompt Examples:\\n\")",
        "for name, prompt in system_prompts.items():",
        "    print(f\"{name}: {prompt}\")",
        "",
        "print(\"\\n\ud83d\udca1 System prompts shape the model's behavior!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Deployment Options",
        "",
        "Ways to share your chatbot with others!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Deployment options",
        "deployment_options = {",
        "    \"Local\": {",
        "        \"command\": \"demo.launch(share=False)\",",
        "        \"pros\": \"Fast, secure, free\",",
        "        \"cons\": \"Only you can access\",",
        "    },",
        "    \"Gradio Share\": {",
        "        \"command\": \"demo.launch(share=True)\",",
        "        \"pros\": \"Creates public link, easy to share\",",
        "        \"cons\": \"Temporary link (72 hours)\",",
        "    },",
        "    \"Hugging Face Spaces\": {",
        "        \"command\": \"Upload to HF Spaces\",",
        "        \"pros\": \"Permanent, professional, free tier\",",
        "        \"cons\": \"Requires account setup\",",
        "    },",
        "    \"Cloud Server\": {",
        "        \"command\": \"Deploy to AWS/GCP/Azure\",",
        "        \"pros\": \"Full control, scalable\",",
        "        \"cons\": \"Costs money, more setup\",",
        "    },",
        "}",
        "",
        "print(\"Deployment Options:\\n\")",
        "for option, details in deployment_options.items():",
        "    print(f\"\ud83d\udccc {option}\")",
        "    print(f\"   Command: {details['command']}\")",
        "    print(f\"   Pros: {details['pros']}\")",
        "    print(f\"   Cons: {details['cons']}\")",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Complete Example",
        "",
        "Full working chatbot with all features!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Complete chatbot implementation",
        "def create_full_chatbot(model):",
        "    \"\"\"Create complete chatbot with all features\"\"\"",
        "    ",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"My GPT Chatbot\") as app:",
        "        gr.Markdown(\"# \ud83e\udd16 Your Custom GPT Chatbot\")",
        "        gr.Markdown(\"Built from scratch in this ML learning journey!\")",
        "        ",
        "        with gr.Row():",
        "            with gr.Column(scale=3):",
        "                chatbot = gr.Chatbot(height=500, label=\"Chat\")",
        "                ",
        "                with gr.Row():",
        "                    msg = gr.Textbox(",
        "                        placeholder=\"Ask me anything...\",",
        "                        show_label=False,",
        "                        scale=4",
        "                    )",
        "                    submit = gr.Button(\"Send \ud83d\ude80\", scale=1)",
        "                ",
        "                clear = gr.ClearButton([msg, chatbot])",
        "            ",
        "            with gr.Column(scale=1):",
        "                gr.Markdown(\"### \u2699\ufe0f Settings\")",
        "                ",
        "                temperature = gr.Slider(",
        "                    0.1, 2.0, value=0.8, step=0.1,",
        "                    label=\"Temperature\"",
        "                )",
        "                ",
        "                max_length = gr.Slider(",
        "                    50, 500, value=150, step=50,",
        "                    label=\"Max Length\"",
        "                )",
        "                ",
        "                system_prompt = gr.Dropdown(",
        "                    choices=list(system_prompts.keys()),",
        "                    value=\"Helpful Assistant\",",
        "                    label=\"Role\"",
        "                )",
        "        ",
        "        gr.Markdown(",
        "            \"\"\"",
        "            ---",
        "            ### \ud83d\udcca Model Info",
        "            - Architecture: Transformer (GPT-style)",
        "            - Parameters: Custom trained",
        "            - Training: Phase 1-4 curriculum",
        "            ",
        "            ### \ud83c\udfaf Tips",
        "            - Be specific in your questions",
        "            - Adjust temperature for creativity",
        "            - Try different roles for varied responses",
        "            \"\"\"",
        "        )",
        "        ",
        "        # Connect events",
        "        msg.submit(chat_interface, [msg, chatbot, temperature, max_length], chatbot)",
        "        submit.click(chat_interface, [msg, chatbot, temperature, max_length], chatbot)",
        "    ",
        "    return app",
        "",
        "print(\"\\n\u2705 Complete chatbot ready!\")",
        "print(\"Run: app = create_full_chatbot(model)\")",
        "print(\"Then: app.launch()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary",
        "",
        "### What We Built:",
        "1. **Chat Interface** - Beautiful Gradio UI",
        "2. **Generation Controls** - Temperature, length, etc.",
        "3. **Prompt Engineering** - Better inputs = better outputs",
        "4. **System Prompts** - Shape model behavior",
        "5. **Deployment Options** - Share with the world!",
        "",
        "### Key Insights:",
        "- UI makes models accessible",
        "- Prompt engineering is crucial",
        "- Temperature controls creativity",
        "- System prompts set behavior",
        "- Many ways to deploy",
        "",
        "### \ud83c\udf89 CONGRATULATIONS! \ud83c\udf89",
        "",
        "You've completed the entire journey:",
        "- \u2705 Phase 1: Neural Networks",
        "- \u2705 Phase 2: Text & Embeddings",
        "- \u2705 Phase 3: Transformers",
        "- \u2705 Phase 4: GPT & Chat Interface",
        "",
        "You built GPT from scratch and created a chatbot! ",
        "",
        "### What's Next?",
        "- Train on larger datasets",
        "- Experiment with bigger models",
        "- Try fine-tuning on specific tasks",
        "- Deploy and share your chatbot",
        "- Keep learning and building!",
        "",
        "### Resources:",
        "- Hugging Face Transformers: https://huggingface.co/transformers/",
        "- OpenAI GPT Papers: https://openai.com/research/",
        "- Attention Is All You Need: https://arxiv.org/abs/1706.03762",
        "",
        "**You're now a GPT builder! Keep exploring! \ud83d\ude80**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}